Day1:
一个小的简单爬虫，爬取京东手机页面的手机价格，名称等基本信息
Day2:
一个更简单的爬虫，爬取一个小说网页上的一点信息，主要是接合使用了urllib和re
Day3:
一个爬取网站图片并保存到本地的爬虫，主要是使用了bs4来解析html，获取img属性等
Day4:
使用scrapy爬取豆瓣电影的一些信息
Day5:
Leetcode twoSum
Day6:
廖大神的例子，将他的python教程html下载并转换成pdf，转换后的pdf还有一些问题待完善
Day7:
爬去Python Jupyter notebook，封装了一下昨天的htmltopdf的爬取代码
Day8:
对昨天的爬虫做修改，因为本爬虫比参考实例多一层目录，在爬取工作上修改完善，成功生成python使用文档的pdf文件,顺便研究了一下分词，明天爬个数据做个词云
Day9:
从豆瓣爬一部最新上映的电影的短评，然后使用jieba分词并使用wordcloud绘制词云
Day10:
登录豆瓣，使用cookie实现验证码登录
Day11:
爬虫练习，xpath解析还是不明确，需要修改

