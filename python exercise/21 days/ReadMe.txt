Day1:
一个小的简单爬虫，爬取京东手机页面的手机价格，名称等基本信息
Day2:
一个更简单的爬虫，爬取一个小说网页上的一点信息，主要是接合使用了urllib和re
Day3:
一个爬取网站图片并保存到本地的爬虫，主要是使用了bs4来解析html，获取img属性等
Day4:
使用scrapy爬取豆瓣电影的一些信息
Day5:
Leetcode twoSum
Day6:
廖大神的例子，将他的python教程html下载并转换成pdf，转换后的pdf还有一些问题待完善
Day7:
爬去Python Jupyter notebook，封装了一下昨天的htmltopdf的爬取代码
Day8:
对昨天的爬虫做修改，因为本爬虫比参考实例多一层目录，在爬取工作上修改完善，成功生成python使用文档的pdf文件,顺便研究了一下分词，明天爬个数据做个词云
Day9:
从豆瓣爬一部最新上映的电影的短评，然后使用jieba分词并使用wordcloud绘制词云
Day10:
登录豆瓣，使用cookie实现验证码登录
Day11:
爬虫练习，xpath解析还是不明确，需要修改
Day12:
修改昨天的部分&学习一个简单的爬取股票信息的爬虫
Day13:
机器学习实战k邻近
Day14:
knn,以及使用sklearn的LinearRegression
Day15:
numpy学习，使用jupyter notebook
Day16:
pandas学习
Day17:
学习神经网络基础,一个无隐藏层的神经网络的梯度下降和一个简单的有隐藏层的神经网络的正向传播
Day18:
神经网络反向传播